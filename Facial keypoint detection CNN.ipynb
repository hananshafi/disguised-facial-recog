{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, MaxPooling2D,MaxPooling2D,AveragePooling2D, Dense, GlobalAveragePooling2D\n",
    "from keras import optimizers, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dropout, Flatten, Concatenate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "dim = 227\n",
    "tbCallBack = callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "#train\n",
    "df1 = pd.read_csv('train.csv',header = None)\n",
    "print \"Program started\"\n",
    "X = np.stack([cv2.imread(\"trainimages/\"+str(img)) for img in df1.iloc[:,-1]]).astype(np.float)[:, :, :, np.newaxis]\n",
    "print \"Resizing done\"\n",
    "y = np.vstack(df1.iloc[:,:-1].values)\n",
    "X_train = X / 255\n",
    "y_train = y\n",
    "\n",
    "\n",
    "#test\n",
    "df2 = pd.read_csv('test.csv',header = None)\n",
    "print \"Program started\"\n",
    "X = np.stack([cv2.imread(\"testimages/\"+str(img)) for img in df2.iloc[:,-1]]).astype(np.float)[:, :, :, np.newaxis]\n",
    "print \"Resizing done\"\n",
    "y = np.vstack(df2.iloc[:,:-1].values)\n",
    "X_test = X / 255\n",
    "y_test = y\n",
    "\n",
    "\n",
    "print \"Model Started\"\n",
    "\n",
    "X_train = X_train.reshape(3500,dim,dim,3)\n",
    "X_test = X_test.reshape(500,dim,dim,3)\n",
    "\n",
    "print \"X_train.shape\" + str(X_train.shape)\n",
    "print \"y_train.shape\" + str(y_train.shape)\n",
    "print \"X_test.shape\" + str(X_test.shape)\n",
    "print \"y_test.shape\" + str(y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(batch_size = 50, input_shape=(dim,dim,3)))\n",
    "model.add(Conv2D(8,kernel_size=(2,2),strides=(1, 1), padding='same', data_format=None, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "\n",
    "model.add(Conv2D(8, kernel_size=(2,2), strides=(1, 1), padding='same', data_format=None, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(2,2), strides=(1, 1), padding='same', data_format=None, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(2,2), strides=(1, 1), padding='same', data_format=None, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, kernel_size=(5,5), strides=(1, 1), padding='same', data_format=None, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "model.add(Conv2D(32, kernel_size=(5,5), strides=(1, 1), padding='same', data_format=None, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(64, kernel_size=(5,5), strides=(1, 1), padding='same', data_format=None, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "model.add(Conv2D(64, kernel_size=(5,5), strides=(1, 1), padding='same', data_format=None, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(128, kernel_size=(5,5), strides=(1, 1), padding='same', data_format=None, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "model.add(Conv2D(128, kernel_size=(5,5), strides=(1, 1), padding='same', data_format=None, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "model.add(Conv2D(256, kernel_size=(2,2), strides=(1, 1), padding='same', data_format=None, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "model.add(Conv2D(256, kernel_size=(2,2), strides=(1, 1), padding='same', data_format=None, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(512, kernel_size=(2,2), strides=(1, 1), padding='same', data_format=None, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "model.add(Conv2D(512, kernel_size=(2,2), strides=(1, 1), padding='same', data_format=None, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid')) \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation=\"relu\"))\n",
    "model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "\n",
    "\n",
    "model.add(Dense(40))\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=50, epochs=1200, verbose=1, validation_split=0.1, shuffle=True,callbacks = [tbCallBack])\n",
    "\n",
    "#saving model\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "#evaluate model\n",
    "scores = model.evaluate(X_test, y_test, verbose=1, batch_size = 50)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
